{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55a8ba18",
   "metadata": {},
   "source": [
    "# Small Example of iDLG on CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124399de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt \n",
    "import skimage \n",
    "import numpy as np \n",
    "from tqdm import tqdm\n",
    "import torch as torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms, datasets\n",
    "from torch.optim.lbfgs import LBFGS\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdabaa31",
   "metadata": {},
   "outputs": [],
   "source": [
    "class iDLG:\n",
    "    def __init__(\n",
    "        self,\n",
    "        model,\n",
    "        orig_img,\n",
    "        label,\n",
    "        device,\n",
    "        *,\n",
    "        seed: int | None = None,\n",
    "        clamp: tuple[float, float] | None = (0.0, 1.0),\n",
    "    ) -> None:\n",
    "        # Respect provided device and keep original dtype of the model/weights\n",
    "        self.device = device if isinstance(device, str) else (device.type if hasattr(device, \"type\") else \"cpu\")\n",
    "        self.model = model.to(self.device)\n",
    "        self.orig_img = orig_img.to(self.device)\n",
    "        self.criterion = nn.CrossEntropyLoss(reduction='sum').to(self.device)\n",
    "        self.label = label.to(self.device)\n",
    "        self.tt = transforms.ToPILImage()\n",
    "        self.clamp = clamp\n",
    "\n",
    "        # Align image dtype to model parameter dtype (usually float32)\n",
    "        self.param_dtype = next(self.model.parameters()).dtype\n",
    "        if self.orig_img.dtype != self.param_dtype:\n",
    "            self.orig_img = self.orig_img.to(self.param_dtype)\n",
    "\n",
    "        if seed is not None:\n",
    "            torch.manual_seed(seed)\n",
    "            torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "    def _infer_label_from_grads(self, orig_grads):\n",
    "        # Map grads to names\n",
    "        named_grads = {name: g for (name, _), g in zip(self.model.named_parameters(), orig_grads)}\n",
    "        last_bias_name = None\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if name.endswith(\".bias\") and param.ndim == 1:\n",
    "                last_bias_name = name  # keep overwriting â†’ last bias\n",
    "\n",
    "        bias_grad = named_grads[last_bias_name]\n",
    "        return torch.argmin(bias_grad).detach().reshape((1,))\n",
    "\n",
    "    def attack(self, iterations=200):\n",
    "        # iDLG training image reconstruction:\n",
    "        self.model.eval()\n",
    "        \n",
    "        # compute original gradients\n",
    "        predicted = self.model(self.orig_img)\n",
    "        loss = self.criterion(predicted, self.label)\n",
    "        orig_grads = torch.autograd.grad(loss, self.model.parameters())\n",
    "        orig_grads = list((_.detach().clone() for _ in orig_grads))\n",
    "\n",
    "        # initialize dummy in the correct iteration, respecting the random seed\n",
    "        # dummy_data = (torch.randn(self.orig_img.size(), dtype=self.param_dtype, device=self.device).requires_grad_(True))\n",
    "        dummy_data = torch.as_tensor(self.orig_img)\n",
    "\n",
    "        # init with ground truth:\n",
    "        label_pred = self._infer_label_from_grads(orig_grads).requires_grad_(False)\n",
    "        optimizer = LBFGS(\n",
    "            [dummy_data], lr=.1, max_iter=50,\n",
    "            tolerance_grad=1e-09, tolerance_change=1e-11,\n",
    "            history_size=100, line_search_fn='strong_wolfe'\n",
    "        )\n",
    "\n",
    "        history = []\n",
    "        losses = []\n",
    "\n",
    "        for iters in tqdm(range(iterations)):\n",
    "            def closure():\n",
    "                optimizer.zero_grad()\n",
    "                dummy_pred = self.model(dummy_data)\n",
    "                dummy_loss = self.criterion(dummy_pred, label_pred)\n",
    "                dummy_dy_dx = torch.autograd.grad(dummy_loss, self.model.parameters(), create_graph=True)\n",
    "                grad_diff = 0\n",
    "                for gx, gy in zip(dummy_dy_dx, orig_grads):\n",
    "                    grad_diff += ((gx - gy) ** 2).sum()\n",
    "                grad_diff.backward()\n",
    "                return grad_diff\n",
    "\n",
    "            optimizer.step(closure)\n",
    "\n",
    "            # Optional: keep dummy within valid input range\n",
    "            if self.clamp is not None:\n",
    "                with torch.no_grad():\n",
    "                    dummy_data.clamp_(self.clamp[0], self.clamp[1])\n",
    "\n",
    "            if iters % 1 == 0:\n",
    "                current_loss = closure()\n",
    "                losses.append(current_loss.item())\n",
    "                history.append(self.tt(dummy_data[0].cpu()))\n",
    "\n",
    "        return dummy_data.detach().numpy().squeeze(), label_pred, history, losses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d673b4a3",
   "metadata": {},
   "source": [
    "### Define Model Architecture "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687b38c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "    def __init__(self, channel: int = 3, hidden: int = 768, num_classes: int = 10):\n",
    "        super(LeNet, self).__init__()\n",
    "        act = nn.Sigmoid\n",
    "        self.body = nn.Sequential(\n",
    "            nn.Conv2d(channel, 12, kernel_size=5, padding=5 // 2, stride=2),\n",
    "            act(),\n",
    "            nn.Conv2d(12, 12, kernel_size=5, padding=5 // 2, stride=2),\n",
    "            act(),\n",
    "            nn.Conv2d(12, 12, kernel_size=5, padding=5 // 2, stride=1),\n",
    "            act(),\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(hidden, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.body(x)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59355798",
   "metadata": {},
   "source": [
    "### Initialize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fde30ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LeNet(num_classes=5)\n",
    "model.load_state_dict(torch.load(\"seed_41_alpha_1.00_th_95_method_None_epoch_1.pth\")['model_state_dict'])\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d04571d",
   "metadata": {},
   "source": [
    "### Get a Datapoint "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc22761",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load an image from cifar10 from your dataloader \n",
    "input_image = torch.Tensor(np.transpose(skimage.io.imread(\"image.png\") / 255, (2, 0, 1))[None, :, :, :])\n",
    "label = torch.Tensor([1]).long() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76a57bf",
   "metadata": {},
   "source": [
    "### Attack "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a606161",
   "metadata": {},
   "outputs": [],
   "source": [
    "idlg = iDLG(model=model, device=torch.device(\"cpu\"), orig_img = input_image, label = torch.tensor([label.item()]), clamp = (0, 1))\n",
    "dummy_data_idlg, label_pred_idlg, history_idlg, losses_idlg = idlg.attack(iterations=1000)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize = (12, 3))\n",
    "ax[0].plot(losses_idlg, 'b-', label = 'Loss')\n",
    "ax[0].set_xlabel('Iteration')\n",
    "ax[0].set_ylabel('Loss')\n",
    "ax[0].legend()\n",
    "ax[1].imshow(np.transpose(dummy_data_idlg, (1, 2, 0)))\n",
    "# ax[1].imshow(history_invgra[34])\n",
    "plt.show()\n",
    "\n",
    "diff = [(np.array(history_idlg[i+1]) - np.array(history_idlg[i])).sum().item() for i in range(len(history_idlg)-1)]\n",
    "plt.plot(diff)\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bachelor-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
