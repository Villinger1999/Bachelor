Train: (50000, 32, 32, 3) (50000, 1)
Test: (10000, 32, 32, 3) (10000, 1)
Round 1/1
Local Epoch [1/2] - Loss: 2.9242
Local Epoch [2/2] - Loss: 2.0103
Client 1 done.
0.0 0.285

------------------------------------------------------------
Sender: LSF System <lsfadmin@hpc.dtu.dk>
Subject: Job 26523933: <train> in cluster <dcc> Done

Job <train> was submitted from host <n-62-27-21> by user <s224227> in cluster <dcc> at Fri Oct 17 13:19:13 2025
Job was executed on host(s) <n-62-31-5>, in queue <hpc>, as user <s224227> in cluster <dcc> at Fri Oct 17 13:19:14 2025
</zhome/d1/b/187261> was used as the home directory.
</zhome/d1/b/187261/Desktop/Bachelor/Bachelor> was used as the working directory.
Started at Fri Oct 17 13:19:14 2025
Terminated at Fri Oct 17 13:19:55 2025
Results reported at Fri Oct 17 13:19:55 2025

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
#!/bin/bash

#BSUB -J train
#BSUB -q hpc
#BSUB -W 2
#BSUB -R "rusage[mem=6G]"
#BSUB -R "select[model == XeonGold6126]"
#BSUB -R "span[hosts=1]"
#BSUB -n 1
#BSUB -o train_%J.out
#BSUB -e train_%J.err

# # Load Python if needed (depends on DTU module system)
module load python/3.10.12  

# Activate your virtual environment
source ~/torch-env/bin/activate

python main.py 1 1 2 64 1
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   32.45 sec.
    Max Memory :                                 419 MB
    Average Memory :                             419.00 MB
    Total Requested Memory :                     6144.00 MB
    Delta Memory :                               5725.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                5
    Run time :                                   99 sec.
    Turnaround time :                            42 sec.

The output (if any) is above this job summary.



PS:

Read file <train_26523933.err> for stderr output of this job.

