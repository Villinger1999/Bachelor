Train: (50000, 32, 32, 3) (50000, 1)
Test: (10000, 32, 32, 3) (10000, 1)
Round 1/4
Local Epoch [1/2] - Loss: 4.7326
Local Epoch [2/2] - Loss: 2.0793
Client 1 done.
Local Epoch [1/2] - Loss: 4.8440
Local Epoch [2/2] - Loss: 1.9653
Client 2 done.
Local Epoch [1/2] - Loss: 4.8623
Local Epoch [2/2] - Loss: 1.9994
Client 3 done.
Local Epoch [1/2] - Loss: 4.9198
Local Epoch [2/2] - Loss: 1.9700
Client 4 done.
Round 2/4
Local Epoch [1/2] - Loss: 2.0250
Local Epoch [2/2] - Loss: 1.6055
Client 1 done.
Local Epoch [1/2] - Loss: 2.0581
Local Epoch [2/2] - Loss: 1.5989
Client 2 done.
Local Epoch [1/2] - Loss: 2.1494
Local Epoch [2/2] - Loss: 1.7034
Client 3 done.
Local Epoch [1/2] - Loss: 2.0415
Local Epoch [2/2] - Loss: 1.5514
Client 4 done.
Round 3/4
Local Epoch [1/2] - Loss: 1.6991
Local Epoch [2/2] - Loss: 1.1637
Client 1 done.
Local Epoch [1/2] - Loss: 1.7065
Local Epoch [2/2] - Loss: 1.1238
Client 2 done.
Local Epoch [1/2] - Loss: 1.8209
Local Epoch [2/2] - Loss: 1.1663
Client 3 done.
Local Epoch [1/2] - Loss: 1.6911
Local Epoch [2/2] - Loss: 1.2902
Client 4 done.
Round 4/4
Local Epoch [1/2] - Loss: 1.3139
Local Epoch [2/2] - Loss: 0.7532
Client 1 done.
Local Epoch [1/2] - Loss: 1.2472
Local Epoch [2/2] - Loss: 0.8668
Client 2 done.
Local Epoch [1/2] - Loss: 1.4079
Local Epoch [2/2] - Loss: 0.8161
Client 3 done.
Local Epoch [1/2] - Loss: 1.2201
Local Epoch [2/2] - Loss: 0.7321
Client 4 done.
0.0 0.28

------------------------------------------------------------
Sender: LSF System <lsfadmin@hpc.dtu.dk>
Subject: Job 26527028: <train> in cluster <dcc> Done

Job <train> was submitted from host <n-62-27-21> by user <s224227> in cluster <dcc> at Fri Oct 17 13:37:17 2025
Job was executed on host(s) <n-62-31-22>, in queue <hpc>, as user <s224227> in cluster <dcc> at Fri Oct 17 13:37:18 2025
</zhome/d1/b/187261> was used as the home directory.
</zhome/d1/b/187261/Desktop/Bachelor/Bachelor> was used as the working directory.
Started at Fri Oct 17 13:37:18 2025
Terminated at Fri Oct 17 13:38:49 2025
Results reported at Fri Oct 17 13:38:49 2025

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
#!/bin/bash

#BSUB -J train
#BSUB -q hpc
#BSUB -W 60
#BSUB -R "rusage[mem=10G]"
#BSUB -R "select[model == XeonGold6126]"
#BSUB -R "span[hosts=1]"
#BSUB -n 1
#BSUB -o train_%J.out
#BSUB -e train_%J.err

# # Load Python if needed (depends on DTU module system)
module load python/3.10.12  

# Activate your virtual environment
source ~/torch-env/bin/activate

python main.py 4 4 2 64 1
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   77.67 sec.
    Max Memory :                                 485 MB
    Average Memory :                             485.00 MB
    Total Requested Memory :                     10240.00 MB
    Delta Memory :                               9755.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                5
    Run time :                                   189 sec.
    Turnaround time :                            92 sec.

The output (if any) is above this job summary.



PS:

Read file <train_26527028.err> for stderr output of this job.

